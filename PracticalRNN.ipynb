{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import TextProcess, TextGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128    #Input features to the LSTM\n",
    "hidden_size = 1024  #Number of LSTM units\n",
    "num_layers = 1\n",
    "num_epochs = 20\n",
    "batch_size = 20\n",
    "timesteps = 30\n",
    "learning_rate = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = TextProcess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_tensor = corpus.get_data('alice.txt', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(corpus.dictionary)\n",
    "num_batches = rep_tensor.shape[1]//timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1652])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model\n",
    "model = TextGenerator(vocab_size, embed_size, hidden_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "embed.weight \t torch.Size([5995, 128])\n",
      "lstm.weight_ih_l0 \t torch.Size([4096, 128])\n",
      "lstm.weight_hh_l0 \t torch.Size([4096, 1024])\n",
      "lstm.bias_ih_l0 \t torch.Size([4096])\n",
      "lstm.bias_hh_l0 \t torch.Size([4096])\n",
      "linear.weight \t torch.Size([5995, 1024])\n",
      "linear.bias \t torch.Size([5995])\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.002, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [4560272192, 4560272048, 4560272336, 4560272408, 4560272480, 4560272552, 4560272624]}]\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nnbootcamp/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 8.70119857788086\n",
      "Epoch [2/20], Loss: 6.043236255645752\n",
      "Epoch [3/20], Loss: 5.209585666656494\n",
      "Epoch [4/20], Loss: 4.527743339538574\n",
      "Epoch [5/20], Loss: 3.9210705757141113\n",
      "Epoch [6/20], Loss: 3.469094753265381\n",
      "Epoch [7/20], Loss: 3.019498586654663\n",
      "Epoch [8/20], Loss: 2.5557782649993896\n",
      "Epoch [9/20], Loss: 2.1801047325134277\n",
      "Epoch [10/20], Loss: 1.7460548877716064\n",
      "Epoch [11/20], Loss: 1.3886160850524902\n",
      "Epoch [12/20], Loss: 1.1579561233520508\n",
      "Epoch [13/20], Loss: 0.946799635887146\n",
      "Epoch [14/20], Loss: 0.6713408827781677\n",
      "Epoch [15/20], Loss: 0.4528830945491791\n",
      "Epoch [16/20], Loss: 0.30095961689949036\n",
      "Epoch [17/20], Loss: 0.1882040947675705\n",
      "Epoch [18/20], Loss: 0.12131280452013016\n",
      "Epoch [19/20], Loss: 0.08757255971431732\n",
      "Epoch [20/20], Loss: 0.07487738877534866\n",
      "1154.1750988960266: seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "print(\"Start training the model\")\n",
    "for epoch in range(num_epochs):\n",
    "    # Set zeros to be the initial hidden and cell states\n",
    "    states = (torch.zeros(num_layers, batch_size, hidden_size),\n",
    "             torch.zeros(num_layers, batch_size, hidden_size))\n",
    "    for i in range(0, rep_tensor.size(1) - timesteps, timesteps):\n",
    "        # Get mini-batch inputs and targets\n",
    "        inputs = rep_tensor[:, i:i+timesteps]\n",
    "        targets = rep_tensor[:, (i+1):(i+1)+timesteps]\n",
    "        # 600 = 20 * 30 = batch_size * timesteps\n",
    "        outputs, _ = model(inputs, states) # outputs is 600x1\n",
    "        loss = loss_fn(outputs, targets.reshape(-1)) # reshape to be 600\n",
    "        \n",
    "        # Backpropagation and Weight Update\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Add gradient clipping to prevent `Gradient Vanishing`\n",
    "        nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        \n",
    "        step = (i+1) // timesteps\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "end = time.time()\n",
    "print(f\"{end - start}: seconds\")\n",
    "torch.save(model.state_dict(), 'lstm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextGenerator(\n",
       "  (embed): Embedding(5995, 128)\n",
       "  (lstm): LSTM(128, 1024, batch_first=True)\n",
       "  (linear): Linear(in_features=1024, out_features=5995, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained model from file\n",
    "model = TextGenerator(vocab_size, embed_size, hidden_size, num_layers)\n",
    "model.load_state_dict(torch.load('lstm.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "embed.weight \t torch.Size([5995, 128])\n",
      "lstm.weight_ih_l0 \t torch.Size([4096, 128])\n",
      "lstm.weight_hh_l0 \t torch.Size([4096, 1024])\n",
      "lstm.bias_ih_l0 \t torch.Size([4096])\n",
      "lstm.bias_hh_l0 \t torch.Size([4096])\n",
      "linear.weight \t torch.Size([5995, 1024])\n",
      "linear.bias \t torch.Size([5995])\n",
      "Optimizer's state_dict:\n",
      "state \t {4560272192: {'step': 1100, 'exp_avg': tensor([[ 0.0000, -0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]), 'exp_avg_sq': tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])}, 4560272048: {'step': 1100, 'exp_avg': tensor([[ 4.6614e-06, -6.8353e-06,  1.9828e-06,  ..., -8.1123e-07,\n",
      "         -1.5593e-06, -3.4868e-06],\n",
      "        [ 4.2755e-06, -5.2054e-06, -2.5085e-06,  ...,  5.2786e-06,\n",
      "          3.8014e-06,  8.3735e-06],\n",
      "        [-1.8204e-06, -2.1919e-06,  2.4617e-06,  ..., -7.1552e-06,\n",
      "         -4.3336e-06, -1.8488e-06],\n",
      "        ...,\n",
      "        [ 1.1186e-05,  2.2512e-05, -2.5906e-06,  ..., -2.5922e-05,\n",
      "          1.1306e-05, -1.3947e-05],\n",
      "        [ 5.7846e-06,  1.4584e-05,  1.1036e-05,  ...,  2.0666e-08,\n",
      "          1.1236e-05, -1.5617e-06],\n",
      "        [-5.0988e-06, -7.5650e-06, -6.4558e-06,  ..., -8.7147e-06,\n",
      "          2.0772e-05, -7.3477e-06]]), 'exp_avg_sq': tensor([[1.1765e-09, 9.2418e-10, 9.2418e-10,  ..., 5.5578e-10, 1.0357e-09,\n",
      "         5.8018e-10],\n",
      "        [1.7077e-09, 1.2367e-09, 1.3046e-09,  ..., 1.0802e-09, 1.3581e-09,\n",
      "         1.2298e-09],\n",
      "        [4.3508e-09, 4.9444e-09, 4.2254e-09,  ..., 2.2809e-09, 4.5306e-09,\n",
      "         2.7090e-09],\n",
      "        ...,\n",
      "        [1.3631e-08, 1.1664e-08, 1.2935e-08,  ..., 1.1836e-08, 1.7691e-08,\n",
      "         9.6439e-09],\n",
      "        [3.3556e-08, 3.9145e-08, 3.3434e-08,  ..., 1.5224e-08, 2.8993e-08,\n",
      "         1.8560e-08],\n",
      "        [1.1061e-08, 1.0540e-08, 1.7888e-08,  ..., 9.6196e-09, 1.8896e-08,\n",
      "         8.8379e-09]])}, 4560272336: {'step': 1100, 'exp_avg': tensor([[-9.7463e-08,  1.5923e-07, -3.9798e-07,  ..., -2.6137e-08,\n",
      "          3.4657e-08,  1.0312e-07],\n",
      "        [ 2.4438e-08,  1.6368e-08,  3.9944e-07,  ...,  2.1421e-07,\n",
      "          1.2551e-07, -1.9285e-07],\n",
      "        [-1.8363e-07, -1.0094e-06, -2.9395e-07,  ...,  3.5452e-07,\n",
      "         -2.5904e-07, -4.1035e-07],\n",
      "        ...,\n",
      "        [-6.8494e-07,  1.1568e-06, -3.5557e-06,  ..., -2.3332e-07,\n",
      "          6.3378e-07, -1.6671e-06],\n",
      "        [ 1.0177e-07,  1.3075e-07, -2.6520e-08,  ..., -2.1912e-07,\n",
      "          1.2986e-06, -3.2070e-08],\n",
      "        [-1.5898e-06,  5.7407e-07, -8.4750e-08,  ..., -1.2297e-06,\n",
      "          7.2977e-07, -5.3009e-07]]), 'exp_avg_sq': tensor([[1.2808e-11, 3.6248e-11, 1.7721e-10,  ..., 3.0500e-11, 8.6015e-11,\n",
      "         4.7866e-11],\n",
      "        [2.1642e-11, 1.8259e-11, 3.0037e-10,  ..., 3.1770e-11, 1.4239e-10,\n",
      "         6.7436e-11],\n",
      "        [5.9765e-11, 2.7663e-11, 5.2479e-10,  ..., 3.5525e-11, 1.8935e-10,\n",
      "         1.4325e-10],\n",
      "        ...,\n",
      "        [4.6171e-10, 4.4803e-10, 6.1556e-09,  ..., 8.3936e-10, 2.0495e-09,\n",
      "         1.5842e-09],\n",
      "        [1.0577e-09, 1.0125e-09, 9.7149e-09,  ..., 1.3381e-09, 7.7079e-09,\n",
      "         2.7847e-09],\n",
      "        [7.6692e-10, 5.0235e-10, 5.7767e-09,  ..., 1.0519e-09, 1.6323e-09,\n",
      "         4.5807e-09]])}, 4560272408: {'step': 1100, 'exp_avg': tensor([ 7.9284e-06, -4.0721e-06, -1.2140e-06,  ...,  3.1104e-05,\n",
      "         1.2548e-05,  4.9258e-06]), 'exp_avg_sq': tensor([1.0052e-09, 1.5389e-09, 4.7281e-09,  ..., 2.6227e-08, 3.2230e-08,\n",
      "        3.0211e-08])}, 4560272480: {'step': 1100, 'exp_avg': tensor([ 7.9284e-06, -4.0721e-06, -1.2140e-06,  ...,  3.1104e-05,\n",
      "         1.2548e-05,  4.9258e-06]), 'exp_avg_sq': tensor([1.0052e-09, 1.5389e-09, 4.7281e-09,  ..., 2.6227e-08, 3.2230e-08,\n",
      "        3.0211e-08])}, 4560272552: {'step': 1100, 'exp_avg': tensor([[-1.4800e-05, -3.9382e-06,  3.4703e-05,  ..., -1.8156e-07,\n",
      "         -3.5215e-06, -8.1139e-08],\n",
      "        [ 4.0869e-05, -1.2309e-05, -6.0723e-06,  ..., -2.0063e-05,\n",
      "          7.6535e-06, -1.7396e-05],\n",
      "        [ 6.1085e-09,  7.8167e-09,  1.3479e-09,  ..., -5.9764e-09,\n",
      "         -1.5479e-09,  6.4557e-09],\n",
      "        ...,\n",
      "        [ 4.4756e-09,  3.3946e-08, -6.2207e-08,  ..., -3.0938e-08,\n",
      "          1.9647e-08,  4.7265e-08],\n",
      "        [ 2.4788e-10,  7.5427e-10,  2.0748e-11,  ..., -5.3951e-10,\n",
      "          3.1405e-10,  4.9021e-10],\n",
      "        [ 2.3136e-10,  6.9464e-10, -4.2001e-11,  ..., -5.1349e-10,\n",
      "          2.8569e-10,  4.7678e-10]]), 'exp_avg_sq': tensor([[1.2521e-08, 9.3201e-09, 6.9707e-08,  ..., 3.3482e-10, 1.0404e-08,\n",
      "         4.5473e-11],\n",
      "        [7.7238e-09, 7.0878e-10, 3.7624e-10,  ..., 2.8413e-09, 3.6897e-10,\n",
      "         1.3494e-09],\n",
      "        [8.4244e-11, 7.1979e-12, 3.3151e-10,  ..., 3.8070e-12, 2.8861e-11,\n",
      "         1.4912e-11],\n",
      "        ...,\n",
      "        [1.1282e-11, 2.5440e-10, 1.9127e-09,  ..., 4.7672e-12, 1.3368e-10,\n",
      "         8.9995e-12],\n",
      "        [3.1292e-13, 1.3289e-13, 4.9745e-14,  ..., 9.6982e-14, 3.7313e-13,\n",
      "         5.4372e-14],\n",
      "        [2.8283e-13, 1.1625e-13, 4.4768e-14,  ..., 8.5379e-14, 3.6244e-13,\n",
      "         4.7751e-14]])}, 4560272624: {'step': 1100, 'exp_avg': tensor([-5.6242e-05,  7.0920e-05,  5.1303e-08,  ...,  1.4274e-07,\n",
      "         4.4709e-09,  4.2032e-09]), 'exp_avg_sq': tensor([1.5285e-07, 3.1572e-08, 3.5693e-09,  ..., 3.9422e-09, 2.3125e-11,\n",
      "        2.5497e-11])}}\n",
      "param_groups \t [{'lr': 0.002, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [4560272192, 4560272048, 4560272336, 4560272408, 4560272480, 4560272552, 4560272624]}]\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5995"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5976]])\n",
      "Pick word: editions,\n",
      "Predicted word is: delay\t\t\t4158. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: fight\t\t\t3969. \n",
      "Predicted word is: her\t\t\t16. \n",
      "Predicted word is: head\t\t\t550. \n",
      "Predicted word is: off\t\t\t252. \n",
      "Predicted word is: a\t\t\t44. \n",
      "Predicted word is: queer\t\t\t970. \n",
      "Predicted word is: pig,’\t\t\t3207. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: King\t\t\t3780. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: The\t\t\t165. \n",
      "Predicted word is: waistcoat-pocket,\t\t\t142. \n",
      "Predicted word is: as\t\t\t55. \n",
      "Predicted word is: it\t\t\t34. \n",
      "Predicted word is: had\t\t\t28. \n",
      "Predicted word is: not\t\t\t173. \n",
      "Predicted word is: help\t\t\t946. \n",
      "Predicted word is: and\t\t\t20. \n",
      "Predicted word is: was\t\t\t7. \n",
      "Predicted word is: as\t\t\t55. \n",
      "Predicted word is: she\t\t\t27. \n",
      "Predicted word is: went\t\t\t161. \n",
      "Predicted word is: on\t\t\t18. \n",
      "Predicted word is: a\t\t\t44. \n",
      "Predicted word is: sort\t\t\t290. \n",
      "Predicted word is: of\t\t\t13. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: roof\t\t\t888. \n",
      "Predicted word is: to\t\t\t9. \n",
      "Predicted word is: on\t\t\t18. \n",
      "Predicted word is: one\t\t\t218. \n",
      "Predicted word is: hand,\t\t\t2055. \n",
      "Predicted word is: and\t\t\t20. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: Queen?’\t\t\t3931. \n",
      "Predicted word is: here.’\t\t\t3176. \n",
      "Predicted word is: Alice\t\t\t6. \n",
      "Predicted word is: went\t\t\t161. \n",
      "Predicted word is: back\t\t\t574. \n",
      "Predicted word is: to\t\t\t9. \n",
      "Predicted word is: you\t\t\t285. \n",
      "Predicted word is: my\t\t\t394. \n",
      "Predicted word is: mind\t\t\t52. \n",
      "Predicted word is: that\t\t\t110. \n",
      "Predicted word is: Cheshire\t\t\t2938. \n",
      "Predicted word is: to\t\t\t9. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: ‘Then\t\t\t2051. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: moral\t\t\t4040. \n",
      "Predicted word is: it\t\t\t34. \n",
      "Predicted word is: was\t\t\t7. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: poor\t\t\t554. \n",
      "Predicted word is: hands,\t\t\t1114. \n",
      "Predicted word is: know,\t\t\t1345. \n",
      "Predicted word is: sir,\t\t\t2369. \n",
      "Predicted word is: if\t\t\t251. \n",
      "Predicted word is: it\t\t\t34. \n",
      "Predicted word is: was\t\t\t7. \n",
      "Predicted word is: a\t\t\t44. \n",
      "Predicted word is: serpent.\t\t\t2641. \n",
      "Predicted word is: wag\t\t\t3190. \n",
      "Predicted word is: do\t\t\t372. \n",
      "Predicted word is: something\t\t\t1197. \n",
      "Predicted word is: of\t\t\t13. \n",
      "Predicted word is: her\t\t\t16. \n",
      "Predicted word is: lap\t\t\t1044. \n",
      "Predicted word is: of\t\t\t13. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: Mouse,\t\t\t1216. \n",
      "Predicted word is: frowning,\t\t\t1481. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: can\t\t\t782. \n",
      "Predicted word is: easily\t\t\t1757. \n",
      "Predicted word is: The\t\t\t165. \n",
      "Predicted word is: Duchess\t\t\t2821. \n",
      "Predicted word is: to\t\t\t9. \n",
      "Predicted word is: see\t\t\t151. \n",
      "Predicted word is: it\t\t\t34. \n",
      "Predicted word is: you\t\t\t285. \n",
      "Predicted word is: like\t\t\t167. \n",
      "Predicted word is: a\t\t\t44. \n",
      "Predicted word is: thing\t\t\t722. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: sands\t\t\t4586. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: The\t\t\t165. \n",
      "Predicted word is: Rabbit\t\t\t79. \n",
      "Predicted word is: say,\t\t\t463. \n",
      "Predicted word is: all\t\t\t117. \n",
      "Predicted word is: his\t\t\t1055. \n",
      "Predicted word is: mouth\t\t\t2433. \n",
      "Predicted word is: for\t\t\t57. \n",
      "Predicted word is: fear\t\t\t228. \n",
      "Sample [100/500] and save to results.txt\n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: The\t\t\t165. \n",
      "Predicted word is: Rabbit\t\t\t79. \n",
      "Predicted word is: noticed\t\t\t201. \n",
      "Predicted word is: that\t\t\t110. \n",
      "Predicted word is: she\t\t\t27. \n",
      "Predicted word is: went\t\t\t161. \n",
      "Predicted word is: back\t\t\t574. \n",
      "Predicted word is: to\t\t\t9. \n",
      "Predicted word is: be\t\t\t69. \n",
      "Predicted word is: found\t\t\t177. \n",
      "Predicted word is: herself\t\t\t176. \n",
      "Predicted word is: talking\t\t\t380. \n",
      "Predicted word is: comfortable,\t\t\t4728. \n",
      "Predicted word is: and\t\t\t20. \n",
      "Predicted word is: then\t\t\t130. \n",
      "Predicted word is: she\t\t\t27. \n",
      "Predicted word is: too\t\t\t196. \n",
      "Predicted word is: much\t\t\t94. \n",
      "Predicted word is: surprised\t\t\t800. \n",
      "Predicted word is: very\t\t\t11. \n",
      "Predicted word is: much\t\t\t94. \n",
      "Predicted word is: surprised\t\t\t800. \n",
      "Predicted word is: at\t\t\t114. \n",
      "Predicted word is: quite\t\t\t119. \n",
      "Predicted word is: enough--I\t\t\t1961. \n",
      "Predicted word is: I’m\t\t\t400. \n",
      "Predicted word is: very\t\t\t11. \n",
      "Predicted word is: much,\t\t\t2328. \n",
      "Predicted word is: so\t\t\t87. \n",
      "Predicted word is: much\t\t\t94. \n",
      "Predicted word is: surprised\t\t\t800. \n",
      "Predicted word is: for\t\t\t57. \n",
      "Predicted word is: you?’\t\t\t2071. \n",
      "Predicted word is: things\t\t\t289. \n",
      "Predicted word is: between\t\t\t2856. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: right\t\t\t305. \n",
      "Predicted word is: used\t\t\t1015. \n",
      "Predicted word is: to\t\t\t9. \n",
      "Predicted word is: be\t\t\t69. \n",
      "Predicted word is: herself\t\t\t176. \n",
      "Predicted word is: talking\t\t\t380. \n",
      "Predicted word is: to\t\t\t9. \n",
      "Predicted word is: her\t\t\t16. \n",
      "Predicted word is: became\t\t\t3203. \n",
      "Predicted word is: because\t\t\t618. \n",
      "Predicted word is: or\t\t\t25. \n",
      "Predicted word is: judge,\t\t\t1726. \n",
      "Predicted word is: and\t\t\t20. \n",
      "Predicted word is: do\t\t\t372. \n",
      "Predicted word is: something\t\t\t1197. \n",
      "Predicted word is: were\t\t\t203. \n",
      "Predicted word is: trying\t\t\t488. \n",
      "Predicted word is: every\t\t\t489. \n",
      "Predicted word is: now\t\t\t675. \n",
      "Predicted word is: and\t\t\t20. \n",
      "Predicted word is: he\t\t\t931. \n",
      "Predicted word is: spoke,\t\t\t2632. \n",
      "Predicted word is: and\t\t\t20. \n",
      "Predicted word is: seemed\t\t\t118. \n",
      "Predicted word is: to\t\t\t9. \n",
      "Predicted word is: turn\t\t\t2391. \n",
      "Predicted word is: one\t\t\t218. \n",
      "Predicted word is: hand,\t\t\t2055. \n",
      "Predicted word is: at\t\t\t114. \n",
      "Predicted word is: once,\t\t\t1447. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: Queen?’\t\t\t3931. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: The\t\t\t165. \n",
      "Predicted word is: Hatter\t\t\t3245. \n",
      "Predicted word is: upon\t\t\t212. \n",
      "Predicted word is: their\t\t\t329. \n",
      "Predicted word is: friends\t\t\t621. \n",
      "Predicted word is: like\t\t\t167. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: Duchess’s\t\t\t4134. \n",
      "Predicted word is: ‘I\t\t\t265. \n",
      "Predicted word is: once\t\t\t24. \n",
      "Predicted word is: more,\t\t\t1556. \n",
      "Predicted word is: thank\t\t\t2197. \n",
      "Predicted word is: tittered\t\t\t1563. \n",
      "Predicted word is: a\t\t\t44. \n",
      "Predicted word is: sort\t\t\t290. \n",
      "Predicted word is: of\t\t\t13. \n",
      "Predicted word is: his\t\t\t1055. \n",
      "Predicted word is: mouth\t\t\t2433. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: presented\t\t\t1659. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: cakes,\t\t\t2241. \n",
      "Predicted word is: and\t\t\t20. \n",
      "Predicted word is: at\t\t\t114. \n",
      "Predicted word is: once,\t\t\t1447. \n",
      "Predicted word is: and\t\t\t20. \n",
      "Sample [200/500] and save to results.txt\n",
      "Predicted word is: was\t\t\t7. \n",
      "Predicted word is: not\t\t\t173. \n",
      "Predicted word is: yet!’\t\t\t4786. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: ‘It\t\t\t1698. \n",
      "Predicted word is: tells\t\t\t3346. \n",
      "Predicted word is: a\t\t\t44. \n",
      "Predicted word is: little\t\t\t367. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: ‘but\t\t\t1702. \n",
      "Predicted word is: they’re\t\t\t2733. \n",
      "Predicted word is: to\t\t\t9. \n",
      "Predicted word is: think\t\t\t93. \n",
      "Predicted word is: very\t\t\t11. \n",
      "Predicted word is: much,\t\t\t2328. \n",
      "Predicted word is: WHAT\t\t\t2440. \n",
      "Predicted word is: thin--and\t\t\t4865. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: Foundation,\t\t\t5679. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: house,\t\t\t1081. \n",
      "Predicted word is: and\t\t\t20. \n",
      "Predicted word is: was\t\t\t7. \n",
      "Predicted word is: still\t\t\t300. \n",
      "Predicted word is: in\t\t\t38. \n",
      "Predicted word is: another\t\t\t159. \n",
      "Predicted word is: moment\t\t\t160. \n",
      "Predicted word is: Alice\t\t\t6. \n",
      "Predicted word is: went\t\t\t161. \n",
      "Predicted word is: on\t\t\t18. \n",
      "Predicted word is: talking:\t\t\t968. \n",
      "Predicted word is: donations\t\t\t5609. \n",
      "Predicted word is: upon\t\t\t212. \n",
      "Predicted word is: her\t\t\t16. \n",
      "Predicted word is: became\t\t\t3203. \n",
      "Predicted word is: at\t\t\t114. \n",
      "Predicted word is: all:\t\t\t4832. \n",
      "Predicted word is: said\t\t\t272. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: Foundation,\t\t\t5679. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: roses\t\t\t3637. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: court,\t\t\t4800. \n",
      "Predicted word is: she\t\t\t27. \n",
      "Predicted word is: added,\t\t\t3758. \n",
      "Predicted word is: or\t\t\t25. \n",
      "Predicted word is: judge,\t\t\t1726. \n",
      "Predicted word is: in\t\t\t38. \n",
      "Predicted word is: a\t\t\t44. \n",
      "Predicted word is: little\t\t\t367. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: label,\t\t\t588. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: label,\t\t\t588. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: the\t\t\t3. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted word is: jury-box\t\t\t4959. \n",
      "Predicted word is: with\t\t\t80. \n",
      "Predicted word is: you,\t\t\t645. \n",
      "Predicted word is: and\t\t\t20. \n",
      "Predicted word is: there\t\t\t208. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: ‘Then\t\t\t2051. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: moral\t\t\t4040. \n",
      "Predicted word is: of\t\t\t13. \n",
      "Predicted word is: his\t\t\t1055. \n",
      "Predicted word is: first\t\t\t505. \n",
      "Predicted word is: to\t\t\t9. \n",
      "Predicted word is: look\t\t\t186. \n",
      "Predicted word is: up\t\t\t73. \n",
      "Predicted word is: into\t\t\t30. \n",
      "Predicted word is: a\t\t\t44. \n",
      "Predicted word is: Gryphon,\t\t\t4178. \n",
      "Predicted word is: and,\t\t\t964. \n",
      "Predicted word is: as\t\t\t55. \n",
      "Predicted word is: he\t\t\t931. \n",
      "Predicted word is: spoke,\t\t\t2632. \n",
      "Predicted word is: and\t\t\t20. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: about\t\t\t174. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: Gryphon.\t\t\t4189. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: The\t\t\t165. \n",
      "Predicted word is: Mock\t\t\t4009. \n",
      "Predicted word is: Turtle\t\t\t4169. \n",
      "Predicted word is: to\t\t\t9. \n",
      "Predicted word is: give\t\t\t856. \n",
      "Predicted word is: them\t\t\t344. \n",
      "Predicted word is: even\t\t\t250. \n",
      "Predicted word is: if\t\t\t251. \n",
      "Sample [300/500] and save to results.txt\n",
      "Predicted word is: you\t\t\t285. \n",
      "Predicted word is: my\t\t\t394. \n",
      "Predicted word is: tail.\t\t\t1315. \n",
      "Predicted word is: would\t\t\t68. \n",
      "Predicted word is: take\t\t\t144. \n",
      "Predicted word is: a\t\t\t44. \n",
      "Predicted word is: low,\t\t\t950. \n",
      "Predicted word is: weak\t\t\t2494. \n",
      "Predicted word is: and\t\t\t20. \n",
      "Predicted word is: he\t\t\t931. \n",
      "Predicted word is: spoke.\t\t\t1534. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: ‘any\t\t\t4520. \n",
      "Predicted word is: pleaded\t\t\t1756. \n",
      "Predicted word is: Alice.\t\t\t1650. \n",
      "Predicted word is: ‘And\t\t\t365. \n",
      "Predicted word is: so\t\t\t87. \n",
      "Predicted word is: suddenly:\t\t\t3223. \n",
      "Predicted word is: and\t\t\t20. \n",
      "Predicted word is: was\t\t\t7. \n",
      "Predicted word is: very\t\t\t11. \n",
      "Predicted word is: much,\t\t\t2328. \n",
      "Predicted word is: bottle\t\t\t581. \n",
      "Predicted word is: different.\t\t\t980. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: and\t\t\t20. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: like\t\t\t167. \n",
      "Predicted word is: changing\t\t\t2545. \n",
      "Predicted word is: said\t\t\t272. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: way\t\t\t96. \n",
      "Predicted word is: all\t\t\t117. \n",
      "Predicted word is: his\t\t\t1055. \n",
      "Predicted word is: mouth\t\t\t2433. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: Gutenberg\t\t\t5349. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: ‘It\t\t\t1698. \n",
      "Predicted word is: tells\t\t\t3346. \n",
      "Predicted word is: it\t\t\t34. \n",
      "Predicted word is: you\t\t\t285. \n",
      "Predicted word is: know\t\t\t1002. \n",
      "Predicted word is: one,’\t\t\t3474. \n",
      "Predicted word is: on\t\t\t18. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: fee\t\t\t5419. \n",
      "Predicted word is: for\t\t\t57. \n",
      "Predicted word is: fear\t\t\t228. \n",
      "Predicted word is: on\t\t\t18. \n",
      "Predicted word is: one\t\t\t218. \n",
      "Predicted word is: hand,\t\t\t2055. \n",
      "Predicted word is: he\t\t\t931. \n",
      "Predicted word is: was\t\t\t7. \n",
      "Predicted word is: Mystery,’\t\t\t4311. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: porpoise,\t\t\t4523. \n",
      "Predicted word is: it\t\t\t34. \n",
      "Predicted word is: was!’\t\t\t2320. \n",
      "Predicted word is: Alice,\t\t\t555. \n",
      "Predicted word is: looking\t\t\t1673. \n",
      "Predicted word is: for\t\t\t57. \n",
      "Predicted word is: life\t\t\t811. \n",
      "Predicted word is: to\t\t\t9. \n",
      "Predicted word is: be\t\t\t69. \n",
      "Predicted word is: removed,’\t\t\t3954. \n",
      "Predicted word is: a\t\t\t44. \n",
      "Predicted word is: fish\t\t\t4529. \n",
      "Predicted word is: thought\t\t\t46. \n",
      "Predicted word is: she\t\t\t27. \n",
      "Predicted word is: ought\t\t\t111. \n",
      "Predicted word is: to\t\t\t9. \n",
      "Predicted word is: or\t\t\t25. \n",
      "Predicted word is: judge,\t\t\t1726. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: with\t\t\t80. \n",
      "Predicted word is: you,\t\t\t645. \n",
      "Predicted word is: and\t\t\t20. \n",
      "Predicted word is: I’ve\t\t\t268. \n",
      "Predicted word is: kept\t\t\t942. \n",
      "Predicted word is: on\t\t\t18. \n",
      "Predicted word is: a\t\t\t44. \n",
      "Predicted word is: tree.\t\t\t3219. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: ‘It\t\t\t1698. \n",
      "Predicted word is: tells\t\t\t3346. \n",
      "Predicted word is: to\t\t\t9. \n",
      "Predicted word is: on\t\t\t18. \n",
      "Predicted word is: one\t\t\t218. \n",
      "Predicted word is: hand,\t\t\t2055. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: little\t\t\t367. \n",
      "Predicted word is: passage:\t\t\t3627. \n",
      "Predicted word is: I\t\t\t103. \n",
      "Predicted word is: wish\t\t\t395. \n",
      "Predicted word is: I’d\t\t\t1892. \n",
      "Predicted word is: only\t\t\t562. \n",
      "Predicted word is: not\t\t\t173. \n",
      "Sample [400/500] and save to results.txt\n",
      "Predicted word is: yet!’\t\t\t4786. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: ‘In\t\t\t1538. \n",
      "Predicted word is: my\t\t\t394. \n",
      "Predicted word is: hand\t\t\t433. \n",
      "Predicted word is: being\t\t\t1099. \n",
      "Predicted word is: possessed\t\t\t5619. \n",
      "Predicted word is: at\t\t\t114. \n",
      "Predicted word is: last,\t\t\t1686. \n",
      "Predicted word is: I’ll\t\t\t601. \n",
      "Predicted word is: on\t\t\t18. \n",
      "Predicted word is: talking:\t\t\t968. \n",
      "Predicted word is: else’s\t\t\t5061. \n",
      "Predicted word is: wish\t\t\t395. \n",
      "Predicted word is: I’d\t\t\t1892. \n",
      "Predicted word is: had\t\t\t28. \n",
      "Predicted word is: a\t\t\t44. \n",
      "Predicted word is: small\t\t\t532. \n",
      "Predicted word is: faint\t\t\t2318. \n",
      "Predicted word is: out\t\t\t95. \n",
      "Predicted word is: like\t\t\t167. \n",
      "Predicted word is: a\t\t\t44. \n",
      "Predicted word is: low,\t\t\t950. \n",
      "Predicted word is: weak\t\t\t2494. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: was\t\t\t7. \n",
      "Predicted word is: Mystery,’\t\t\t4311. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: Duchess’s\t\t\t4134. \n",
      "Predicted word is: little\t\t\t367. \n",
      "Predicted word is: passage:\t\t\t3627. \n",
      "Predicted word is: and\t\t\t20. \n",
      "Predicted word is: shouted\t\t\t2229. \n",
      "Predicted word is: Alice.\t\t\t1650. \n",
      "Predicted word is: ‘And\t\t\t365. \n",
      "Predicted word is: how\t\t\t162. \n",
      "Predicted word is: he\t\t\t931. \n",
      "Predicted word is: was\t\t\t7. \n",
      "Predicted word is: still\t\t\t300. \n",
      "Predicted word is: in\t\t\t38. \n",
      "Predicted word is: a\t\t\t44. \n",
      "Predicted word is: confused\t\t\t1632. \n",
      "Predicted word is: do,\t\t\t378. \n",
      "Predicted word is: why\t\t\t1390. \n",
      "Predicted word is: I\t\t\t103. \n",
      "Predicted word is: am\t\t\t984. \n",
      "Predicted word is: I\t\t\t103. \n",
      "Predicted word is: am\t\t\t984. \n",
      "Predicted word is: I\t\t\t103. \n",
      "Predicted word is: used\t\t\t1015. \n",
      "Predicted word is: to\t\t\t9. \n",
      "Predicted word is: be\t\t\t69. \n",
      "Predicted word is: removed,’\t\t\t3954. \n",
      "Predicted word is: you\t\t\t285. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: began\t\t\t320. \n",
      "Predicted word is: below\t\t\t2627. \n",
      "Predicted word is: you\t\t\t285. \n",
      "Predicted word is: only\t\t\t562. \n",
      "Predicted word is: said\t\t\t272. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: other\t\t\t615. \n",
      "Predicted word is: work\t\t\t2604. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: ‘It\t\t\t1698. \n",
      "Predicted word is: tells\t\t\t3346. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: top\t\t\t253. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: top\t\t\t253. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: treacle\t\t\t3568. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: the\t\t\t3. \n",
      "Predicted word is: top\t\t\t253. \n",
      "Predicted word is: Gutenberg\t\t\t5349. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: can\t\t\t782. \n",
      "Predicted word is: easily\t\t\t1757. \n",
      "Predicted word is: thought\t\t\t46. \n",
      "Predicted word is: they\t\t\t202. \n",
      "Predicted word is: walked\t\t\t491. \n",
      "Predicted word is: on\t\t\t18. \n",
      "Predicted word is: one\t\t\t218. \n",
      "Predicted word is: hand,\t\t\t2055. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: thousand\t\t\t282. \n",
      "Predicted word is: it.)\t\t\t1583. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: <eos>\t\t\t5. \n",
      "Predicted word is: ‘When\t\t\t4017. \n",
      "Predicted word is: take\t\t\t144. \n",
      "Predicted word is: a\t\t\t44. \n",
      "Predicted word is: confused\t\t\t1632. \n",
      "Predicted word is: to\t\t\t9. \n",
      "Sample [500/500] and save to results.txt\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "filename = 'results.txt'\n",
    "with torch.no_grad():\n",
    "    with open(filename, 'w') as f:\n",
    "        # Set the initial hidden one cell states\n",
    "        # batch_size = 1 Because we feed only 1 vector\n",
    "        state = (torch.zeros(num_layers, 1, hidden_size),\n",
    "                 torch.zeros(num_layers, 1, hidden_size))\n",
    "        # Select one word id randomly and convert it to shape (1,1)\n",
    "\n",
    "        # I need to compare Fawaz version and my version. Then let it be \n",
    "        # reproducible program\n",
    "        # input = torch.tensor([[9]])\n",
    "        input = torch.randint(0, vocab_size, (1,)).long().unsqueeze(1)\n",
    "        print(input)\n",
    "        print(f\"Pick word: {corpus.dictionary.idx2word[input.item()]}\")\n",
    "\n",
    "        for i in range(500):\n",
    "            output, _ = model(input, state)\n",
    "\n",
    "            prob = output.exp()\n",
    "            word_id = torch.multinomial(prob, num_samples=1).item()\n",
    "\n",
    "            input.fill_(word_id)\n",
    "            print(f\"Predicted word is: {corpus.dictionary.idx2word[input.item()]}\\t\\t\\t{word_id}. \")\n",
    "            \n",
    "            # Write the results to file\n",
    "            word = corpus.dictionary.idx2word[word_id]\n",
    "            word = '\\n' if word == '<eos>' else word + ' '\n",
    "            f.write(word)\n",
    "            \n",
    "            if (i+1) % 100 == 0:\n",
    "                print(f\"Sample [{i+1}/{500}] and save to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1361)\n"
     ]
    }
   ],
   "source": [
    "max_value = torch.max(output)\n",
    "print(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0401,  0.0060, -0.0380,  ..., -0.0294, -0.0329,  0.0561]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0, 1898]])\n"
     ]
    }
   ],
   "source": [
    "idx = (output == max_value).nonzero()\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1898"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[0][0].item()\n",
    "idx[0][1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plate'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.dictionary.idx2word[idx[0][1].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5026]])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randint(0, vocab_size, (1,)).long().unsqueeze(1)\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER\n",
      "I.\n",
      "Down\n",
      "the\n",
      "Rabbit-Hole\n",
      "<eos>\n",
      "<eos>\n",
      "Alice\n",
      "was\n",
      "beginning\n",
      "to\n",
      "get\n",
      "very\n",
      "tired\n",
      "of\n",
      "sitting\n",
      "by\n",
      "her\n",
      "sister\n",
      "on\n",
      "the\n",
      "<eos>\n",
      "bank,\n",
      "and\n",
      "of\n",
      "having\n",
      "nothing\n",
      "to\n",
      "do:\n",
      "once\n",
      "or\n",
      "twice\n",
      "she\n",
      "had\n",
      "peeped\n",
      "into\n",
      "the\n",
      "<eos>\n",
      "book\n",
      "her\n",
      "sister\n",
      "was\n",
      "reading,\n",
      "but\n",
      "it\n",
      "had\n",
      "no\n",
      "pictures\n",
      "or\n",
      "conversations\n"
     ]
    }
   ],
   "source": [
    "for i in [ 0,  1,  2,  3,  4,  5,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
    "        17, 18,  3,  5, 19, 20, 13, 21, 22,  9, 23, 24, 25, 26, 27, 28, 29, 30,\n",
    "         3,  5, 31, 16, 17,  7, 32, 33, 34, 28, 35, 36, 25, 37]:\n",
    "    print(corpus.dictionary.idx2word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "30\n",
      "60\n",
      "90\n",
      "120\n",
      "150\n",
      "180\n",
      "210\n",
      "240\n",
      "270\n",
      "300\n",
      "330\n",
      "360\n",
      "390\n",
      "420\n",
      "450\n",
      "480\n",
      "510\n",
      "540\n",
      "570\n",
      "600\n",
      "630\n",
      "660\n",
      "690\n",
      "720\n",
      "750\n",
      "780\n",
      "810\n",
      "840\n",
      "870\n",
      "900\n",
      "930\n",
      "960\n",
      "990\n",
      "1020\n",
      "1050\n",
      "1080\n",
      "1110\n",
      "1140\n",
      "1170\n",
      "1200\n",
      "1230\n",
      "1260\n",
      "1290\n",
      "1320\n",
      "1350\n",
      "1380\n",
      "1410\n",
      "1440\n",
      "1470\n",
      "1500\n",
      "1530\n",
      "1560\n",
      "1590\n",
      "1620\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, rep_tensor.size(1) - timesteps, timesteps):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
